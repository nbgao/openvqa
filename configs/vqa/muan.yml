# Network
MODEL_USE: muan
LAYER: 10
HIDDEN_SIZE: 768
FF_SIZE: 3072
MULTI_HEAD: 12
DROPOUT_R: 0.1
FLAT_MLP_SIZE: 512
FLAT_GLIMPSES: 1
FLAT_OUT_SIZE: 1024
USE_BBOX_FEAT: False

# Execution
BATCH_SIZE: 64
LR_BASE: 0.00017
LR_DECAY_R: 0.2
LR_DECAY_LIST: [10, 12]
WARMUP_EPOCH: 3
MAX_EPOCH: 13
GRAD_NORM_CLIP: -1
GRAD_ACCU_STEPS: 2
LOSS_FUNC: bce
LOSS_REDUCTION: sum
OPT: Adam
OPT_PARAMS: {betas: '(0.9, 0.99)', eps: '1e-9'}
